---
title: "p8105_hw6_yc3508"
author: "Yama Chang"
date: "2019/11/24"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)
library(lubridate)
library(forcats)
library(modelr)
library(mgcv)
library(purrr)
library(ggplot2)
library(patchwork)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d

scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))

set.seed(1)
```

## Problem 1

#### Linear Model and Cross Validation

1.1 Read and tidy the birthweight data

```{r}
birthweight = read_csv(file = "./data/birthweight.csv", col_types = NULL, col_names = TRUE) %>%
  janitor::clean_names() 


class(birthweight$wtgain)
```

```{r}
birthweight = birthweight %>% 
  drop_na() %>% 
  mutate(
    babysex = as.factor(recode(babysex, `1` = "male", `2` = "female")),
    frace = as.factor(recode(frace, `1` = "White", `2` = "Black", `3` = "Asian", `4` = "Puerto Rican", `8` = "Other", `9` = "Unknown")),
    malform = as.factor(recode(malform, `0` = "absent", `1` = "present")),
    mrace = as.factor(recode(frace, `1` = "White", `2` = "Black", `3` = "Asian", `4` = "Puerto Rican", `8` = "Other"))
  ) %>% 
  mutate(
    frace = relevel(frace, "White"),
    mrace = relevel(mrace, "White")
  )
```

1.2 Build a regression model to predict baby birthweight

According to [Secker-Walker & Vacek, 2003](https://www.ncbi.nlm.nih.gov/pubmed/12507527) and [Catov et al., 2015](https://www.ncbi.nlm.nih.gov/pubmed/26667251), the effect of smoking, gestational age, maternal weight gain during pregnancy are associated to infant birthweight. Also, race disparities are related to birthweight and birth size. Therefore, we propose `smoken`, `wtgain`, `bhead`, `blength`, `mrace`, `gaweeks` as predictors in this regression model, since we hyphothesized that the biological and environmental change (i.e., weight gain, smoking behavior, gestational age) of mother during pregnant and baby's birth size (e.g., baby’s head circumference, baby's length) at birth might influence baby birthweight. Also, we wanted to examine whether the race of mother would show difference of birth weight of babies.

```{r}
bw = lm(bwt ~ smoken + wtgain + bhead + blength + mrace + gaweeks, data = birthweight)

bw %>% 
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  mutate(term = str_replace(term, "^mrace", "mom_race: ")) %>% 
  knitr::kable(digits = 3)
```

1.3 model residuals

```{r}
bw_model = modelr::add_residuals(birthweight, bw)
bw_model = modelr::add_predictions(bw_model, bw)

bw_model %>% 
  ggplot(aes(x = pred, y = resid, color = resid)) + 
  geom_point(alpha = .5) + 
  theme(legend.position = "right") +
  labs(
    x = "Fitted values",
    y = "Residuals",
    title = "Regression diagnostics: Residuals against fitted values"
  )
```

1.4 Compare to two other model

__Model 1: using length at birth and gestational age as predictors__
```{r}
bw1 = lm(bwt ~ blength + gaweeks, data = birthweight)
```

__Model 2: using head circumference, length, sex, and all interactions (including the three-way interaction) between these__
```{r}
bw2 = lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * bhead + bhead * blength * babysex, data = birthweight)
```

__Fit these three models and obtain RMSEs__

```{r}
cv_df = 
  crossv_mc(birthweight, 100) 

cv_df = cv_df %>% 
  mutate(
    model0 = map(train, ~lm(bwt ~ smoken + wtgain + bhead + blength + mrace + gaweeks, data = .)),
    model1 = map(train, ~lm(bwt ~ blength + gaweeks, data = .)),
    model2 = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * bhead + bhead * blength * babysex, data = .)),
  ) %>% 
  mutate(
    rmse_model0 = map2_dbl(model0, test, ~rmse(model = .x, data = .y)),
    rmse_model1 = map2_dbl(model1, test, ~rmse(model = .x, data = .y)),
    rmse_model2 = map2_dbl(model2, test, ~rmse(model = .x, data = .y))
  )

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse, fill = model)) + 
  geom_violin() +
  labs(
    x = "Model",
    y = "RMSE",
    title = "The distribution of RMSE values for each model"
  ) +
  scale_x_discrete(labels=c("model0" = "Model 0: Base", "model1" = "Model 1: Main effect",
                              "model2" = "Model 2: Interation"))
```

By comparison of these three models, we found that "model 0: base" can predict the birthweight most accurate.

## Problem 2

#### Bootstrapping

```{r include=FALSE}
library(p8105.datasets)

weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

set.seed(1)
```

Simple linear regression to 2017 Central Park weather data

```{r}
lm(tmax ~ tmin, data = weather_df) %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)
```

Using bootstrap function to repeat the analysis

__Estimates of log(β̂ 0∗β̂ 1)__
```{r}
boot_sample = weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  select(term, estimate) %>% 
  pivot_wider(
    names_from = "term",
    values_from = "estimate") %>% 
  unnest() %>% 
  janitor::clean_names() %>% 
  mutate(
    log_estimate = log10(intercept * tmin)
  )
```

__Estimates of r square__

```{r}
boot_sample_2 = weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::glance)) %>% 
  unnest(results) %>% 
  select(r.squared)
```

__Plot the distribution of log(β̂ 0∗β and r squarê __

```{r}
plotA = boot_sample %>% ggplot(aes(x = log_estimate)) + geom_density() + labs(x = "Estimate: log(β̂ 0∗β̂ 1)", title = "Distribution of Estimates")
plotB = boot_sample_2 %>% ggplot(aes(x = r.squared)) + geom_density() + labs(x = "Estimate: r square")

plotA + plotB
```

Both distribution do not have heavy tails, indicating these two bootstrapping samples do not have extensive outliers. Even though the distribution of r square is slightly skewed in the left tail, we can conclude that both estimates are normal distributions. 

__95% confidence interval for r̂ 2 and log(β̂ 0∗β̂ 1)__

```{r}
quantile(pull(boot_sample, log_estimate), probs = c(0.025, 0.975)) %>%
  knitr::kable()

quantile(pull(boot_sample_2, r.squared), probs = c(0.025, 0.975)) %>%
  knitr::kable()
```

The 95% confidence interval of log(β̂ 0∗β̂ 1)is (0.853, 0.894).

The 95% confidence interval of r square is (0.893, 0.927).